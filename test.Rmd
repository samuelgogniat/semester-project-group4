---
title: Implementation of an analysis tool for travel mode detection in R
subtitle: a rule-based approach
authors: Severin Aicher and Samuel Gogniat
output: 
  html_document:
      fig_caption: yes
      code_folding: hide
editor_options: 
  chunk_output_type: console
---
```{r}
#| echo: false
#| warning: false
#| message: false

#loading libraries

library("readr")
library("dplyr")
library("sf")
library("ggplot2")
library("zoo")
library("lubridate")
library("tidyr")
library("gridExtra")
library("cvms")

```
## Abstract

text...

## 1 Introduction

Mobility data plays a crucial role for traffic planners, public transport providers, and authorities as it serves as the foundation for transportation modeling and optimization of services and routing (Netsche). In the past, this data was primarily collected through surveys, but today, the widespread use of smartphones with GPS capabilities allows for data collection on a much larger scale (Yang). However, GPS observations alone provide only geometric and temporal data, and additional information needs to be extracted if necessary (Zhan). One particularly important attribute that requires further analysis is the travel mode (?). (why is it important?)

In this study, we aim to develop a data science procedure in R for  detecting travel modes using GPS data derived from the POSMO-App. Although the POSMO-App has integrated in-time detection, it is prone to errors, most likely due to the lack of pre-processing. Pre-processing is a crucial step as unfiltered data often contains various inaccuracies (Yang). Therefore, our objective is to implement a travel mode detection procedure that can be applied to the data after the collection phase and therefore allows for pre-processing.

Numerous methods have been explored for travel mode detection from GPS data, each with its own advantages and disadvantages (Yang, Sadeghian). Sadeghian et al. (2021) have provided a comprehensive review of these methods, revealing a growing interest in employing machine learning algorithms, particularly unsupervised or deep learning algorithms. Consequently, several recent studies have implemented such data science procedures (??). While these algorithms are capable of handling large amounts of data and achieving highly accurate transport mode detection, the resulting clusters can be challenging to attribute to specific travel modes (Sad, Yang). On the other hand, rule-based methods offer the advantage of including additional GIS layers into the analysis, allowing for the distinction of up to 12 transport modes, which is currently difficult to achieve with machine learning alone (Sadeghian). Hence, although rule-based methods may have lower overall accuracy, they provide improved precision since many machine learning studies only categorize a very limited number of transportation modes (Nitsche, Yang, sad). However, rule-based methods rely on a prior understanding and manually defined rules, making them more time-consuming and less transferable (Sadegian). Consequently, the choice of method strongly depends on the specific objectives of the study.

Considering POSMO's real-life applications, the ability to distinguish as many travel modes as possible takes priority for us. Therefore, this research project aims to implement a rule-based data science procedure in R for identifying travel modes from mobile GPS data. We will assess all travel modes used in our training data, including Walk, Bike, Car, Bus, Train, Tram, and Boat. Additionally, the study will investigate various criteria such as speed, acceleration, and location, utilizing different features such as mean, minimum, and maximum values. These criteria and features will be compared against experimentally defined thresholds. Ultimately, we aim to answer the following research questions:

1.	How can a basic analysis tool for travel mode detection from GPS data be implemented in R and what accuracy is achieved with it?
2.	What are the most effective criteria, features and thresholds for the detection of different travel modes?

## 2 Material and Methods

### 2.1 Datasets & Conceptual Model
```{r}
#| warning: false
#| message: false
#| results: 'hide'

##loading our own dataset:

data <- read_delim("posmo_data/posmo_v3.csv")
head(data) #time is 2h behind
data$datetime <- as.POSIXct(data$datetime, tz = "UTC-2")  #setting time right
data <- arrange(data, datetime) #arrange, so that datetime is in the right order

data <- select(data, datetime, transport_mode, lon_x, lat_y) # keep only the  attributes needed

data <- st_as_sf(data, coords = c("lon_x","lat_y"), crs = 4326) |>  #cs is transformed to 2056
  st_transform(2056)

data_coord <- st_coordinates(data) #coordinates are extracted
data <- cbind(data, data_coord) #coordinates are binded in separate columns
head(data) #first look
summary(data)

##loading swissTLM3D:

roads <- read_sf("background_data/swisstlm3d_2023-03_2056_5728.shp/TLM_STRASSEN/swissTLM3D_TLM_STRASSE.shp") |> #loading roads
  select(OBJEKTART, geometry) |> #choosing attributes needed
  filter(OBJEKTART != "Verbindung" & OBJEKTART != "Raststaette" & OBJEKTART != "Dienstzufahrt" & OBJEKTART != "Verbindung" & OBJEKTART != "Zufahrt " & OBJEKTART != "Klettersteig") |> #deleting factorlevels which are not of interest
  st_transform(2056)#set crs to 2056 (get rid of LN02)

rails <- read_sf("background_data/swisstlm3d_2023-03_2056_5728.shp/TLM_OEV/swissTLM3D_TLM_EISENBAHN.shp") |> #loading rails
  select(VERKEHRSMI, geometry) |> #choosing attributes needed
  rename(OBJEKTART = VERKEHRSMI) |> #rename for merging
    st_transform(2056)#set crs to 2056 (get rid of LN02)

boats <- read_sf("background_data/swisstlm3d_2023-03_2056_5728.shp/TLM_OEV/swissTLM3D_TLM_SCHIFFFAHRT.shp") |> #loading boats
   select(OBJEKTART, geometry) |> #choosing attributes needed
     st_transform(2056)#set crs to 2056 (get rid of LN02)

stops <- read_sf("background_data/swisstlm3d_2023-03_2056_5728.shp/TLM_OEV/swissTLM3D_TLM_HALTESTELLE.shp")|> #loading stops
   select(OBJEKTART, geometry) |> #choosing attributes needed
    st_transform(2056) #set crs to 2056 (get rid of LN02)

##loading POSMO-dataset for validation:

val_data <- read_delim("posmo_data/posmo_validation.csv")
head(val_data) #time is probably behind as well...
val_data$datetime <- as.POSIXct(val_data$datetime, tz = "UTC-2") 
val_data <- arrange(val_data, datetime) 

val_data <- select(val_data, datetime, transport_mode, lon_x, lat_y) # keep only the  attributes needed

val_data <- st_as_sf(val_data, coords = c("lon_x","lat_y"), crs = 4326) |>  #cs is transformed to 2056
  st_transform(2056)

val_data_coord <- st_coordinates(val_data) #coordinates are extracted
val_data <- cbind(val_data, val_data_coord) #coordinates are binded in separate columns
head(val_data) #first look
summary(val_data)

```
To build up our procedure, we used movement data from one of our team members, collected with the POSMO-App over a period of 54 days (18.04.-10.06.2023). Throughout this period, with the sampling rate set to 5 seconds, a total of 61’279 data points were gathered. We proceeded with the following attributes:

-	datetime
-	geometry (X- and Y-Coordinates in CH1903+ LV95)
-	transport_mode (manually corrected and validated in POSMO) 

Additionally, the dataset swissTLM3D was obtained from (QUELLE?), whereof the following feature classes and attributes were used:

-	TLM_STRASSE (OBJEKTART, geometry)
-	TLM_EISENBAHN (VERKEHRSMITTEL, geometry)
-	TLM_SCHIFFFAHRT (OBJEKTART, geometry)
-	TLM_HALTESTELLE (OBJEKTART, geometry)

And last, a second POSMO-dataset provided by one of the other students was used for validation (see chapter ?). This data was collected over a period of 67 days (11.04-16.06.2023) with a sampling rate of 10s, resulting in a total of 46’305 datapoints. It was eventually corrected and validated for travel mode in POSMO as well and the same attributes were analyzed further.

The movement space was conceptualized, based on Laube et al. (2017), as continuous, 2D, and entity-based. Therefore, all datasets were structured as vector data. We modeled the movement as a series of unconstrained, intermittent, and time-stamped fixes. The App collecting GPS data using the Lagrange perspective with event-based, active tracking.

### 2.2 Segmentation & Filtering
```{r}
#| warning: false
#| message: false

##segmentation and filtering:

p1 <- data |> #visualize raw data for example day
  filter(as.Date(datetime) == "2023-04-18") |>
  ggplot(aes(X, Y))+ 
  geom_point()+
  geom_path()+
  coord_equal() +
  theme_classic() +
  ggtitle("(A) raw data")          

data <- data |> #initial segmentation for time gaps > 10s (double the sampling rate)
  mutate(
    timelag = as.numeric(difftime(lead(datetime), datetime, units = "secs")), 
    gap = timelag > 10,
    segment_id = cumsum(gap)
  )

data <- data |> 
  group_by(segment_id) |> #calculating the stepmean with the moving temporal window within each segment
    mutate(
    stepMean = rowMeans(
      cbind(
        sqrt((lag(X, 2) - X)^2 + (lag(Y, 2) - Y)^2),
        sqrt((lag(X, 1) - X)^2 + (lag(Y, 1) - Y)^2),
        sqrt((X - lead(X, 1))^2 + (Y - lead(Y, 1))^2),
        sqrt((X - lead(X, 2))^2 + (Y - lead(Y, 2))^2)
      )
    ),
    static = if_else(is.na(stepMean) | stepMean < 2, T, F) #define every point with a stepMean of less than 2m as static
  )
  
p2 <- data |> #visualize assignment of static points
  filter(as.Date(datetime) == "2023-04-18") |>
  ggplot(aes(X, Y, color=static))+ 
  geom_point()+
  geom_path(group=1)+
  coord_equal() +
  theme_classic() +
  theme(legend.position = c(0.2,0.2))+
  labs(title = "(B) filtering static points")

rle_id <- function(vec) {
    x <- rle(vec)$lengths
    as.factor(rep(seq_along(x), times = x))
} #function to assign unique ID for each segment

data <- data |> 
   ungroup() |> 
    mutate(segment_id = rle_id(static)) |> #assign new segment ID after every break (static points)
    filter(!static) #remove static points

p3 <- data |> #visualize segmentation
  filter(as.Date(datetime) == "2023-04-18") |>
  ggplot(aes(X, Y, color=segment_id))+ 
  geom_point()+
  geom_path()+
  coord_equal() +
  theme_classic() +
  theme(legend.position = "none")+
  labs(title = "(C) segmentation")
    
    
data <- data |> #remove short segments (less than 300m)
  group_by(segment_id) |> 
  mutate(steplength = sqrt((X - lead(X, 1)) ^ 2 + (Y - lead(Y, 1)) ^ 2)) |> 
  filter(sum(steplength, na.rm=T)>300) 

p4 <- data |> #visualize final segments
  filter(as.Date(datetime) == "2023-04-18") |>
  ggplot(aes(X, Y, color=segment_id))+ 
  geom_point()+
  geom_path()+
  coord_equal() +
  theme_classic() +
  theme(legend.position = "none")+
  labs(title = "(D) filtering short segments")
```
In order to assign transport modes to trajectories, the raw data has to be divided into sub-segments representing individual and continuous movements first (yang). Additionally, as according to Laube & Purves (2011), moving objects in the real world almost always exhibit a variety of static and dynamic behaviors, filtering and segmentation is also required for the calculation of movement characteristics. The authors state that without filtering static segments will lead to an underestimation of speed and overestimation of sinuosity. 

Hence, an initial segmentation was performed by assigning a new segment ID whenever the time gap between consecutive fixes exceeded double the sampling rate (10s). This segmentation was performed, as the event-based tracking of the POSMO-App led to large gaps, which needed to be separated for the further calculations. Then, segmentation was performed according to Laube & Purves (2011), were static fixes are classified as those whose average Euclidean distance to other fixes inside a temporal window v is less than some threshold d. Here, a temporal window v of 20 seconds (6 fixes) and a threshold d of 2 meters were chosen and calculations were performed within each segment separately. Further, a new segment ID was assigned after every static period and static fixes were removed. Lastly, sub-segments with a length less than 300m were removed as well. In contrast to Laube & Purves (2011) these short segments were chosen according to a distance and not a temporal scale, as depending on the transport mode used, different temporal scales may be important. For example, a trajectory of a 3 minutes walk may not be of great interest, while a train or bus journey of 3 minutes could already be important. The filtering and segmentation for a exemplary day is visualized step by step in figure 1. Lastly, segments with a average sinuosity (calculated according to chapter 2.3) greater than 2 were removed as well, as they mostly represented GPS errors, as visible in figure 2. During that process, the dataset was segmented into 202 trajectories consisting of 37'942 fixes.
```{r, fig.height=7, fig.align='center', fig.cap = "*Figure 1: segmentation and filtering of trajectories: Raw data (A) was filtered into static and dynamic points (B), then static points were removed and trajectories segmented according to these breaks (C). Last, short segments (<500m) were removed as well (D)*"}
#| warning: false
#| message: false

##plot for segmentation and filtering:

grid.arrange(p1,p2,p3,p4, nrow=2, ncol=2)

```

### 2.3 Calculating Movment Parameters
```{r}
#| warning: false
#| message: false

##calculate moving parameters:

data <- data |> 
  group_by(segment_id) |> #group by segment, so moving window starts for every segment again
  mutate(
    speed = { #distance and time passed is calculated with lag/lead of 2 -> 10s in both directions
      step_minus2 <- sqrt((lag(X, 2) - X) ^ 2 + (lag(Y, 2) - Y) ^ 2)
      time_minus2 <- abs(as.numeric(difftime(lag(datetime, 2), datetime, units = "secs")))
      step_plus2 <- sqrt((X - lead(X, 2)) ^ 2 + (Y - lead(Y, 2)) ^ 2)
      time_plus2 <- as.numeric(difftime(lead(datetime, 2), datetime, units = "secs"))
      (step_minus2/time_minus2 + step_plus2/time_plus2) / 2 #average is taken 
    },
    acc = { #change in speed and time is calculated with lag/lead of 2 -> 10s in both directions
      speed_minus2 <- speed - lag(speed, 2) 
      speed_plus2 <- lead(speed, 2) - speed
      time_minus2 <- abs(as.numeric(difftime(lag(datetime, 2), datetime, units = "secs")))
      time_plus2 <- as.numeric(difftime(lead(datetime, 2), datetime, units = "secs"))
      (speed_minus2/time_minus2 + speed_plus2/time_plus2) / 2 #average is taken
      },
    sin = { #length from every point to next point in window of 5 points is calculated
      d_minus1 <- sqrt((lag(X, 1) - X) ^ 2 + (lag(Y, 1) - Y) ^ 2) 
      d_minus2 <- sqrt((lag(X, 2) - lag(X, 1)) ^ 2 + (lag(Y, 2) - lag(Y, 1)) ^ 2)
      d_plus1  <- sqrt((X - lead(X, 1))^2 + (Y - lead(Y, 1))^2)
      d_plus2  <- sqrt((lead(X, 1) - lead(X, 2))^2 + (lead(Y,1) - lead(Y, 2))^2)
      d_straight <- sqrt((lag(X, 2) - lead(X, 2))^2 + (lag(Y,2) - lead(Y, 2))^2) #distance from first to last point of window
      (d_minus1 + d_minus2 + d_plus1 + d_plus2)/d_straight #ratio between total length and shortest distance
    }
  )

##filter with sinuosity:

p5 <- data |> 
  filter(as.Date(datetime) == "2023-04-22") |> #plot before filter
  ggplot(aes(X, Y, color=segment_id))+ 
  geom_point()+
  geom_path()+
  coord_equal() +
  theme_classic() +
  theme(legend.position = "none")+
  labs(title = "(A) before filtering sinuosity")
    
data <- data |> #filter out segments with hig sinuosity
  group_by(segment_id) |> 
  filter(mean(sin, na.rm=T)<2) 

p6 <- data |> #plot after filter
  filter(as.Date(datetime) == "2023-04-22") |>
  ggplot(aes(X, Y, color=segment_id))+ 
  geom_point()+
  geom_path()+
  coord_equal() +
  theme_classic() +
  theme(legend.position = "none")+
  labs(title = "(B) after filtering sinuosity")
    
```
According to Sadeghian et al. (2011) the most common and powerful variables for transport mode detection are average speed, maximum speed and acceleration. Sinuosity however was not used in any of the papers reviewed by Yang et al. (). Hence, we wanted to integrate sinuosity as well and see if it could be useful for travel mode detection. Accordingly, the movement parameters speed, acceleration and sinuosity were calculated. Speed was computed according to Laube & Purves (2011) using three fixes located inside a temporal window w, which was set to 20 seconds. Acceleration was calculated based on the same principle and defined as the change in velocity over the change in time. The calculation of sinuosity was based on Laube & Purves (2011) as well, where it is defined as the ratio between a nominal track length and the line connecting the first and last points in the sampling window w consisting of 5 fixes. Hence, a sinuosity of 1 represents a straight line, while  increasing sinuosity leads to higher values. All of these calculations were performed for each segment separately.
```{r, fig.align='center', fig.cap = "*Figure 2: after calculation of the moving parameters, segments with a sinuosity higher than 2 were removed as well, shown here for a examplary day before (A) and after the filtering (B)*"}
#| warning: false
#| message: false

##plot for sinuosity filter:

grid.arrange(p5,p6, nrow=1)

```
```{r}
#| warning: false
#| message: false
##calculate summary:
#-> mean, max and min for all three parameters + assignment of POSMO-travel mode

data$transport_mode <- as.factor(data$transport_mode)
data_smry <- data |> 
  group_by(segment_id) |> 
  summarise(
            mean_speed = mean(speed, na.rm=T),
            max_speed = max(speed,na.rm=T),
            min_speed = min(speed,na.rm=T),
            mean_acc = mean(acc, na.rm=T),
            max_acc = max(acc,na.rm=T),
            min_acc = min(acc,na.rm=T),
            mean_sin = mean(sin, na.rm=T),
            max_sin = max(sin,na.rm=T),
            min_sin = min(sin,na.rm=T),
            transport_mode_POSMO = levels(transport_mode)[which.max(table(transport_mode))],
            percentage_tm_POSMO = max(table(transport_mode)) / length(transport_mode) * 100
)


data_smry_long <- pivot_longer(data_smry, #convert from wide to long
                           cols = -c("segment_id","transport_mode_POSMO", "percentage_tm_POSMO","geometry"),
                           names_to = "parameter") 

```
Next the minimum, maximum and average values were computed for the three parameters in every segment. Additionally, every segment was assigned with the adjusted travel mode from POSMO. As segmentation as done here and in POSMO may not be identical, points of the same segments may have several different transportation modes from POSMO. Hence, the transportation mode which was attributed to most points of a segment was chosen. Additionally, the percentage of points per segment attributed with the assigned mode was calculated for possible further analysis. The different features of the three parameters were then plotted by their transportation mode for exploratory analysis (figure 3).
```{r, fig.align='center', fig.cap = "*Figure 3: Exploratory data analysis of the  movement parameters acceleration (acc [m/s^2)]), sinuosity (sin) and speed (speed [m/s]), visualized as the maximal (max), minimum (min) and average (mean) value per segment and  transport mode.*"}
#| warning: false
#| message: false

##plot for EDA:

data_smry_long |> 
ggplot(aes(x=transport_mode_POSMO, y=value, fill=transport_mode_POSMO))+
  geom_boxplot()+
  facet_wrap(~parameter, scales="free_y")+
  theme_classic()+
  theme(
    axis.title.x = element_blank(),
    axis.text.x = element_blank(),
    axis.title.y = element_blank(),
    legend.title = element_blank(),
    legend.position = "bottom")

```
It can be observed, that most transportation modes show similar patterns in terms of the calculated movement parameters, or at least have significant overlaps. Only train trajectories differ considerably from others regarding speed and acceleration. Hence, we have made the decision to approach the transport mode detection by first embedding the trajectories within their geographic context for a better classification. 

### 2.4 Adding Geographic Context
```{r}
#| warning: false
#| message: false

##spatial join: attribute nearest route

background_data <- rbind(roads, rails, boats) #merge the three datasets together
data <- st_join(data, background_data, join = st_nearest_feature)

data$OBJEKTART <- as.factor(data$OBJEKTART)
data_smry_context <- data |> 
  group_by(segment_id) |> 
  summarise(
            nearest_route = levels(OBJEKTART)[which.max(table(OBJEKTART))],  
            percentage_nearest_route = max(table(OBJEKTART)) / length(OBJEKTART) * 100
) |> 
  as_tibble() |> 
  select(-c("geometry"))
```
According to Gschwend (2015) movement patterns are mostly quantified on the basis of geometric properties and the arrangement of the fixes, while the geographic environment surrounding the movement is often neglected, however would provide useful semantics insights. Hence, using external information can increase the performance of the used algorithms substantially (Sadeghian). As the exploratory data analysis of the movement parameters has shown hardly distinguishable features, we wanted to add this approach to our analysis. Hence, as described in chapter 2.1, several feature classes of the swissTLM3D dataset were used and all roads, rails and boat-routes were merged into one background dataset. Next, a spatial join was performed, attributing every fix of the POSMO data to its nearest feature, as visualized in figure 4 for an exemplary day. Lastly, every segment was assigned the feature, which was attributed to most of the points of said segment, the same way it was done for the POSMO travel mode. 
```{r, fig.align='center', fig.cap = "*Figure 4: the spatial join of the POSMO data (point) to the nearest feature of roads, rails and boat lines*"}
#| warning: false
#| message: false

data_01 <- data |> 
  filter(as.Date(datetime) == "2023-04-18") #select example day

bbox <- st_bbox(data_01) #produce a bounding box with that day
clipped_background <- st_crop(background_data, bbox) #cut backround to that bounding box

ggplot()+ #visualize
  geom_sf(data=clipped_background, aes(color=OBJEKTART))+
  geom_sf(data=data_01, alpha=0.4, size=2.5, aes(color=OBJEKTART))+
  theme_classic()+
  theme(legend.position = "bottom")

```
```{r}
#| warning: false
#| message: false

##stop-buffer calculations:

stops <- stops |> 
  rename(stop_type = OBJEKTART)

stops_buffer <- st_buffer(stops, 75) #calculating buffer of 75m around every stop
stop_join <- st_join(data, stops_buffer, join = st_within) #spatial join with POSMO data

first_point <- stop_join |> # a vector is produced, containing the information for the first point of every segment
  group_by(segment_id) |> 
  slice_head() |> #first point is chosen
  pull(stop_type, segment_id) #information about stops is saved

last_point <- stop_join |> #same for last point of every segment
  group_by(segment_id) |> 
  slice_tail() |> 
  pull(stop_type, segment_id)

##merging all parameters:

data_smry_context <- data_smry_context |> 
  cbind(first_point, last_point) 
  
data_class <- left_join(data_smry, data_smry_context, by = "segment_id")

##export for classification (so swisstlm3d has not to be loaded every time)

write.csv(data_class, "output_files/data_class.csv")
```
Further, the feature class TLM_HALTESTELLE of swissTLM3D containing bus, train and boat stops was used as well. A buffer of 75 meters was calculated around every stop and a spatial join was performed  for fixes within these buffers. Next, for every segment the information, if the first and the last point were within a stop-buffer was saved additionally for further analysis. Finally, the moving parameters were merged with the geographical context of the segments into a dataset ready for travel mode classification.

### 2.5 Travel Mode Detection
```{r}
#| warning: false
#| message: false

##travel mode detection:

data_class$travel_mode_det <- NA

data_class <- data_class |> 
  mutate(
    travel_mode_det = case_when(
      nearest_route == "Bahn" | max_speed > 44.44 ~ "Train",
      nearest_route == "Tram" ~ "Tram",
      nearest_route %in% c("Autofaehre", "Personenfaehre") ~ "Boat",
      first_point == "Haltestelle Schiff" & last_point == "Haltestelle Schiff" ~ "Boat",
      (first_point %in% c("Haltestelle Bahn", "Haltestelle Bus")) & (last_point %in% c("Haltestelle Bus", "Haltestelle Bahn")) ~ "Bus",
      max_speed > 12.5 | max_acc > 0.3 ~ "Car",
      mean_speed > 1.94 | max_speed > 5  ~ "Bike",
      TRUE ~ "Walk"
    )
  )
```
Several studies suggest, first separating non-motorized and motorized vehicles and then split up these sub-categories in a second classification step (Zhang, ?). Zhang et. al (2012), for example classified pedestrian, bicylce and motorized vehicles in a first step by using speed, acceleration and heading related parameters. Then, in second step supervised learing algorithms are used to split up motorized journeys to car, bus, trams and trains. However, the moving parameters of our training data seemed not to differ sicnificantly enough, to split up bicycle from Tram, Boat or even Bus journeys. Hence, we decided to use the context information for a first classification and added moving parameters only where they were clearly distinguishable. In that way, train (segment closest to train rails or max speed > 160km/h), tram (segment closest to tram rails), boat (segment closest to boat line or first and last point in boat stop buffer) and bus (first and last stop in bus or train stop buffer) trajectories were classified. This was done in the exact same order, so that trajectories classified as train were not able to be classified again as bus. Next, trajectories with a maximal speed over 45 km/h or maximal acceleration over 0.3 m/s^2 were classified as car segments. Then, segments with a main speed higher than 7km/h or maximal speed over 18km/h were classified as bike rides. And lastly, the remaining segments, which thus had to have a main speed lower than 7km/h were classified as walks. 

### 2.6 Validation
```{r}
#| warning: false
#| message: false

#filter out cable car

val_data <- val_data |> 
  filter(transport_mode != "Cable_Car")

#whole process for validation dataset:

##filtering and segmentation:
      
val_data <- val_data |> #initial segmentation for time gaps > 10s (double the sampling rate)
  mutate(
    timelag = as.numeric(difftime(lead(datetime), datetime, units = "secs")), 
    gap = timelag > 20,
    segment_id = cumsum(gap)
  )

val_data <- val_data |> 
  group_by(segment_id) |> #calculating the stepmean with the moving temporal window within each segment
    mutate(
    stepMean = rowMeans(
      cbind(
        sqrt((lag(X, 1) - X)^2 + (lag(Y, 1) - Y)^2),
        sqrt((X - lead(X, 1))^2 + (Y - lead(Y, 1))^2)
      )
    ),
    static = if_else(is.na(stepMean) | stepMean < 2, T, F) #define every point with a stepMean of less than 2m as static
  )

val_data <- val_data |> 
   ungroup() |> 
    mutate(segment_id = rle_id(static)) |> #assign new segment ID after every break (static points)
    filter(!static) #remove static points

val_data <- val_data |> #remove short segments (less than 300m)
  group_by(segment_id) |> 
  mutate(steplength = sqrt((X - lead(X, 1)) ^ 2 + (Y - lead(Y, 1)) ^ 2)) |> 
  filter(sum(steplength, na.rm=T)>300) 

##calculate moving parameters:

val_data <- val_data |> 
  group_by(segment_id) |> #group by segment, so moving window starts for every segment again
  mutate(
    speed = { #distance and time passed is calculated with lag/lead of 1 -> 10s in both directions
      step_minus1 <- sqrt((lag(X, 1) - X) ^ 2 + (lag(Y, 1) - Y) ^ 2)
      time_minus1 <- abs(as.numeric(difftime(lag(datetime, 2), datetime, units = "secs")))
      step_plus1 <- sqrt((X - lead(X, 1)) ^ 2 + (Y - lead(Y, 1)) ^ 2)
      time_plus1 <- as.numeric(difftime(lead(datetime, 1), datetime, units = "secs"))
      (step_minus1/time_minus1 + step_plus1/time_plus1) / 2 #average is taken 
    },
    acc = { #change in speed and time is calculated with lag/lead of 1 -> 10s in both directions
      speed_minus1 <- speed - lag(speed, 1) 
      speed_plus1 <- lead(speed, 1) - speed
      time_minus1 <- abs(as.numeric(difftime(lag(datetime, 1), datetime, units = "secs")))
      time_plus1 <- as.numeric(difftime(lead(datetime, 1), datetime, units = "secs"))
      (speed_minus1/time_minus1 + speed_plus1/time_plus1) / 2 #average is taken
      },
    sin = { #length from every point to next point in window of 5 points is calculated
      d_minus1 <- sqrt((lag(X, 1) - X) ^ 2 + (lag(Y, 1) - Y) ^ 2) 
      d_minus2 <- sqrt((lag(X, 2) - lag(X, 1)) ^ 2 + (lag(Y, 2) - lag(Y, 1)) ^ 2)
      d_plus1  <- sqrt((X - lead(X, 1))^2 + (Y - lead(Y, 1))^2)
      d_plus2  <- sqrt((lead(X, 1) - lead(X, 2))^2 + (lead(Y,1) - lead(Y, 2))^2)
      d_straight <- sqrt((lag(X, 2) - lead(X, 2))^2 + (lag(Y,2) - lead(Y, 2))^2) #distance from first to last point of window
      (d_minus1 + d_minus2 + d_plus1 + d_plus2)/d_straight #ratio between total length and shortest distance
    }
  )

##filter with sinuosity:

val_data <- val_data |> #filter out segments with hig sinuosity
  group_by(segment_id) |> 
  filter(mean(sin, na.rm=T)<2) 

##calculate summary:
val_data$transport_mode <- as.factor(val_data$transport_mode)
val_data_smry <- val_data |> 
  group_by(segment_id) |> 
  summarise(
            mean_speed = mean(speed, na.rm=T),
            max_speed = max(speed,na.rm=T),
            min_speed = min(speed,na.rm=T),
            mean_acc = mean(acc, na.rm=T),
            max_acc = max(acc,na.rm=T),
            min_acc = min(acc,na.rm=T),
            mean_sin = mean(sin, na.rm=T),
            max_sin = max(sin,na.rm=T),
            min_sin = min(sin,na.rm=T),
            transport_mode_POSMO = levels(transport_mode)[which.max(table(transport_mode))],
            percentage_tm_POSMO = max(table(transport_mode)) / length(transport_mode) * 100
)

val_data <- st_join(val_data, background_data, join = st_nearest_feature)

val_data$OBJEKTART <- as.factor(val_data$OBJEKTART)
val_data_smry_context <- val_data |> 
  group_by(segment_id) |> 
  summarise(
            nearest_route = levels(OBJEKTART)[which.max(table(OBJEKTART))],  
            percentage_nearest_route = max(table(OBJEKTART)) / length(OBJEKTART) * 100
) |> 
  as_tibble() |> 
  select(-c("geometry"))

##stop-buffer calculations:

val_stop_join <- st_join(val_data, stops_buffer, join = st_within) #spatial join with POSMO data

first_point <- val_stop_join |> # a vector is produced, containing the information for the first point of every segment
  group_by(segment_id) |> 
  slice_head() |> #first point is chosen
  pull(stop_type, segment_id) #information about stops is saved

last_point <- val_stop_join |> #same for last point of every segment
  group_by(segment_id) |> 
  slice_tail() |> 
  pull(stop_type, segment_id)

##merging all parameters:

val_data_smry_context <- val_data_smry_context |> 
  cbind(first_point, last_point) 

val_data_class <- left_join(val_data_smry, val_data_smry_context, by = "segment_id")

val_data_class$travel_mode_det <- NA

val_data_class <- val_data_class |> 
  mutate(
    travel_mode_det = case_when(
      nearest_route == "Bahn" | max_speed > 44.44 ~ "Train",
      nearest_route == "Tram" ~ "Tram",
      nearest_route %in% c("Autofaehre", "Personenfaehre") ~ "Boat",
      first_point == "Haltestelle Schiff" & last_point == "Haltestelle Schiff" ~ "Boat",
      (first_point %in% c("Haltestelle Bahn", "Haltestelle Bus")) & (last_point %in% c("Haltestelle Bus", "Haltestelle Bahn")) ~ "Bus",
      max_speed > 12.5 | max_acc > 0.3 ~ "Car",
      mean_speed > 1.94 | max_speed > 5  ~ "Bike",
      TRUE ~ "Walk"
    )
  )
```
First, the output of our travel mode detection was compared to the validated POSMO classification and a confusion matrix was produced. Of cores, as our procedure was built up on that data, this can not be called an actual validation but was rather a comparison with the ground truth. So for a valid predictive validation according to Rykiel et al. (), a second dataset of an other student was used, where travel mode was confirmed in POSMo as well. In that dataset, travel modes walk, bike, bus, tram, train, car and cable car were present. As our training data did not include cable cars, these datapoints had to be filtered out first. Further, as mentioned in chapter 2.1 the sampling rate of that data was 10s, while it was 5s in the training data. Hence, wherever a temporal window was used, number of fixes  were adjusted in order to work with same time-span. However, this was not done for the calculation of sinuosity, where a fixed number of 5 points was used according to Laube & Pulvers (2011). Ultimately, a confusion matrix was produced again and accuracy of our method was calculated.  

## 3 Results
```{r, eval=FALSE}
#| warning: false
#| message: false
#confusion matrix


conf_mat <- confusion_matrix(targets = val_data_class$transport_mode_POSMO, predictions = val_data_class$travel_mode_det)
knitr::kable(conf_mat$Table)



```

## 4 Discussion
